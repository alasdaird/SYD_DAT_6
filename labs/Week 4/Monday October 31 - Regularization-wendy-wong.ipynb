{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab - Regularization\n",
    "\n",
    "## Week 4 Monday 31st October"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TASK: Regularized regression\n",
    "## FUNCTIONS: Ridge, RidgeCV, Lasso, LassoCV\n",
    "## DOCUMENTATION: http://scikit-learn.org/stable/modules/linear_model.html\n",
    "## DATA: Crime (n=319 non-null, p=122, type=regression)\n",
    "## DATA DICTIONARY: http://archive.ics.uci.edu/ml/datasets/Communities+and+Crime\n",
    "\n",
    "## This data set contains data on violent crimes within a community.\n",
    "\n",
    "########## Prepare data ##########\n",
    "# read in data, remove categorical features, remove rows with missing values\n",
    "import pandas as pd\n",
    "crime = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data', header=None, na_values=['?'])\n",
    "crime = crime.iloc[:, 5:]\n",
    "crime.dropna(inplace=True)\n",
    "crime.head()\n",
    "\n",
    "# define X and y\n",
    "X = crime.iloc[:, :-1]\n",
    "y = crime.iloc[:, -1]\n",
    "\n",
    "# split into train/test\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many columns are in X?\n",
    "X.shape\n",
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########## Linear Regression Model Without Regularization ##########\n",
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "lm.coef_\n",
    "# What are these numbers?\n",
    "len(lm.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (no regularization) = 0.233813676495\n"
     ]
    }
   ],
   "source": [
    "# make predictions and evaluate\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "preds = lm.predict(X_test)\n",
    "print 'RMSE (no regularization) =', np.sqrt(metrics.mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Ridge reg.) = 0.164279068049\n"
     ]
    }
   ],
   "source": [
    "########## Ridge Regression Model ##########\n",
    "# ridge regression (alpha must be positive, larger means more regularization)\n",
    "from sklearn.linear_model import Ridge\n",
    "rreg = Ridge(alpha=0.1, normalize=True)\n",
    "rreg.fit(X_train, y_train)\n",
    "rreg.coef_\n",
    "preds = rreg.predict(X_test)\n",
    "print 'RMSE (Ridge reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds))\n",
    "# Is this model better? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Ridge CV reg.) = 0.160913596522\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use RidgeCV to select best alpha\n",
    "from sklearn.linear_model import RidgeCV\n",
    "alpha_range = 10.**np.arange(-2, 3)\n",
    "rregcv = RidgeCV(normalize=True, scoring='mean_squared_error', alphas=alpha_range, cv= 5)\n",
    "rregcv.fit(X_train, y_train)\n",
    "rregcv.alpha_\n",
    "preds = rregcv.predict(X_test)\n",
    "print 'RMSE (Ridge CV reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds))\n",
    "# What is the range of alpha values we are searching over?\n",
    "\n",
    "# we are using regularisation with cross validation with cv\n",
    "\n",
    "##\n",
    "\n",
    "alpha_range\n",
    "rregcv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Lasso reg.) = 0.198165225429\n"
     ]
    }
   ],
   "source": [
    "########## Lasso Regression Model ##########\n",
    "# lasso (alpha must be positive, larger means more regularization)\n",
    "from sklearn.linear_model import Lasso\n",
    "las = Lasso(alpha=0.01, normalize=True)\n",
    "las.fit(X_train, y_train)\n",
    "las.coef_\n",
    "preds = las.predict(X_test)\n",
    "print 'RMSE (Lasso reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Lasso reg.) = 0.164502413721\n"
     ]
    }
   ],
   "source": [
    "# try a smaller alpha\n",
    "las = Lasso(alpha=0.0001, normalize=True)\n",
    "las.fit(X_train, y_train)\n",
    "las.coef_\n",
    "preds = las.predict(X_test)\n",
    "print 'RMSE (Lasso reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (Lasso CV reg.) = 0.164502413721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        , -0.00418625, -0.        ,\n",
       "        0.09573169, -0.        , -0.        , -0.        ,  0.        ,\n",
       "        0.        , -0.0308013 ,  0.        , -0.09352469, -0.08937229,\n",
       "       -0.58628915,  0.        ,  0.16706299, -0.06130851,  0.11966402,\n",
       "       -0.        , -0.        , -0.10046533, -0.01816658, -0.        ,\n",
       "        0.19148624,  0.0281072 , -0.21042443,  0.        , -0.06733447,\n",
       "       -0.30656472,  0.        ,  0.12856465, -0.        , -0.18235778,\n",
       "        0.05534065,  0.14885766,  0.        ,  0.        ,  0.        ,\n",
       "       -0.07395512, -0.        ,  0.16423116, -0.        , -0.3780258 ,\n",
       "       -0.        , -0.        , -0.        ,  0.03341259, -0.        ,\n",
       "        0.22040155, -0.02724104,  0.        , -0.10195256,  0.06214765,\n",
       "        0.0274531 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "       -0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        , -0.2690561 ,  0.        ,  0.        ,  0.35611039,\n",
       "        0.04332233,  0.04845138,  0.0257534 ,  0.12236177, -0.00563988,\n",
       "        0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "       -0.0261296 , -0.        , -0.36526572,  0.        ,  0.        ,\n",
       "        0.3897239 , -0.05088597, -0.11944353, -0.07416446,  0.03742248,\n",
       "        0.15420475,  0.06425829, -0.11141704,  0.        , -0.        ,\n",
       "        0.10241054, -0.        , -0.        ,  0.01559901, -0.00149672,\n",
       "       -0.        ,  0.        ,  0.10057832, -0.        , -0.17578883,\n",
       "       -0.        , -0.        ,  0.02694208,  0.09249571, -0.        ,\n",
       "       -0.        ,  0.01179924, -0.00760995,  0.04291238, -0.06641967,\n",
       "       -0.05050237,  0.1498314 ,  0.        , -0.01623123,  0.03266239,\n",
       "       -0.07961514, -0.02043446])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use LassoCV to select best alpha (tries 100 alphas by default)\n",
    "from sklearn.linear_model import LassoCV\n",
    "alpha_range = 0.01**np.arange(-2,3)\n",
    "lascv = LassoCV(normalize=True, alphas=alpha_range,cv=5)\n",
    "lascv.fit(X_train, y_train)\n",
    "lascv.alpha_\n",
    "lascv.coef_\n",
    "preds = lascv.predict(X_test)\n",
    "print 'RMSE (Lasso CV reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds))\n",
    "lascv.alpha_\n",
    "lascv.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup [Elastic Net](http://scikit-learn.org/stable/modules/linear_model.html#elastic-net) and complete the following.\n",
    "\n",
    "\n",
    "\n",
    "1. What is elastic net?\n",
    "2. How does it work?\n",
    "3. Run elastic net on the above dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "####  1. Elastic Net is linear regression model trained with L1 and L2 prior as regularizer. This combination allows for learning a sparse model where few of the weights are non-zero like Lasso, while still maintaining the regularization properties of Ridge. We control the convex combination of L1 and L2 using the l1_ratio parameter.\n",
    "\n",
    "#### 2. Elastic-net is useful when there are multiple features which are correlated with one another. Lasso is likely to pick one of these at random, while elastic-net is likely to pick both.A practical advantage of trading-off between Lasso and Ridge is it allows Elastic-Net to inherit some of Ridgeâ€™s stability under rotation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-1-5319b069d8de>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-5319b069d8de>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    label='Elastic net coefficients')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "\n",
    "\n",
    "#enet = ElasticNet(alpha=alpha, l1_ratio=0.7)\n",
    "\n",
    "#y_pred_enet = enet.fit(X_train, y_train).predict(X_test)\n",
    "#r2_score_enet = r2_score(y_test, y_pred_enet)\n",
    "#print(enet)\n",
    "#print(\"r^2 on test data : %f\" % r2_score_enet)\n",
    "\n",
    "#plt.plot(enet.coef_, color='lightgreen', linewidth=2,\n",
    "         label='Elastic net coefficients')\n",
    "#plt.plot(lasso.coef_, color='gold', linewidth=2,\n",
    "         label='Lasso coefficients')\n",
    "#plt.plot(coef, '--', color='navy', label='original coefficients')\n",
    "#plt.legend(loc='best')\n",
    "#plt.title(\"Lasso R^2: %f, Elastic Net R^2: %f\"\n",
    "          % (r2_score_lasso, r2_score_enet))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
