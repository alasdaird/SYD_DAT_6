{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYD DAT 6 Lab 1 - Git and Markdown\n",
    "\n",
    "## Homework:\n",
    "\n",
    "#### Setup\n",
    "* Resolve any installation issues before next class.\n",
    "* Make sure you have a github profile and created a repo called \"SYD_DAT_6\"\n",
    "* Clone the class repo (this one!)\n",
    "* Review this [code](../labs/Week 1/00_python_refresher.py) for a recap of some Python basics.\n",
    "\n",
    "#### Communication\n",
    "* Read [Analyzing the Analyzers](http://cdn.oreillystatic.com/oreilly/radarreport/0636920029014/Analyzing_the_Analyzers.pdf) for a useful look at the different types of data scientists. Write down 5 key points you took away from the article\n",
    "* Read about some [Markdown Techniques](http://daringfireball.net/projects/markdown/syntax)\n",
    "* Write a summary of 2 chapters of [The Data Science Handbook](http://www.thedatasciencehandbook.com/) in Markdown and submit a pull request in the Lab Directory\n",
    "\n",
    "#### Programming\n",
    "* Complete the lab from class and the additional Exercise below\n",
    "\n",
    "#### Course Project\n",
    "* Come up with 5 different ideas for your course project. For each one list:\n",
    "  * Overview of your idea\n",
    "  * What data you will use\n",
    "  * What the outcome is that you are trying to achieve\n",
    "  * Any ideas of modelling techniques it may involve\n",
    "\n",
    "**Instructions: copy this file and append your name in the filename, e.g. Homework1_alasdair_douglas.ipynb.\n",
    "Then commit this in your local repository, push it to your github account and create a pull request so I can see your work. Remeber if you get stuck to look at the slides going over Fork, Clone, Commit, Push and Pull request.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exercise 1 - Setup \n",
    "  \n",
    "  1. Python code refresher - completed\n",
    "  2. Git & Github installation - completed\n",
    "  3. Clone repo completed\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Exercise 2 - Communication\n",
    "\n",
    "\n",
    "### Analysing the Analyser\n",
    "\n",
    "1. 5 Key points from the ebook 'Analysing the Analyser':\n",
    "\n",
    "* There is miscommunication from employers in clearly defining the role's required skilla of a data scientist at the interview. Some employers expect the interviewee to be a 'rockstar' that is skilled in all areas in the job spec.\n",
    "* A survey into data scientists produced a clustering of skills and 4 main Self-IDs which includes a Data Business person who is likely to exhibit the characteristics of a female who is skilled in business operations, statistics and machine learning but low on programming who is likely to be a Data Developer who can write code.Few Data Scientists work with terabytes of data.\n",
    "* Survey results indicated that the effectiveness of data scientists was likely from their background in science in comparison to a tool-based education e.g. Masters. Also a post-graduate education in science teaches applied learning which is 'hands-on'.Furthermore, applied learning via internships fror undergraduate degrees is promoted by DJ Patil.\n",
    "* A new hire in an organzation can only perform and produce excellence if he or she has access to data and the management team who adopt and implement their results to drive change in the orgsnisation.\n",
    "* Data science is a team sport that needs the support of funding as well as the rest of the business which includes data infrastucture and the IT department.\n",
    "   \n",
    " ### Data Science Handbook\n",
    "   \n",
    "2. Write a summary of 2 chapters of 'Data Science Handbook' in Markdown and submit a pull request in the lab directory.\n",
    "   \n",
    "DJ Patil encourages a curiosity, ability to test and build products or models to help accelerate one's learning and growth in data science. He spoke of having grit to keep on trying and not giving up when the long road to becoming a data scientist seems impossible. He provided insight that one day an employer will take a risk open the road to become a data scientist and the first 6 months is a huge learning curve and  his mentor recommended that he always test the 'simple things'. Be marketable with the things you are learning and to build , participate in hackathons and learn something that is not taught in academia but relevant to the skills to make you job-ready for data science.\n",
    "Data science is a team sport. Data allows you to access and get involved in areas of the organisation for interaction.\n",
    "\n",
    "Clare Corthell described how she took a big risk and used a collection of Open Source subjects to study over 6 months to complete and develop her own chosen path to become a data scientist and forsake the traditional PhD route of academia to achieve applied skills to make her marketable to employers. She belives that  working in a start-up for data scientists provided her with lots of opportunities to build products and be hands-on on user experience. She promotes taking risks to build and solve problems at work to show leadership and to get experience in data science. She believes that look for employers that embrace your potential in the future and recognise your grit  to try and have a fearless attitude to data when things breakdown.You have to carve your own path into data science.\n",
    "\n",
    "\n",
    "\n",
    "Michaelangelo D'Agostino provided an interesting insight into his love of research which led him to pursue post-graduate studies in astrophysics, his path into data science  was his first  data job for the obama election where he applied his technical academic background, hackathon experience and networking from meetups to learn eveything about R, machine learning, paritcipation in kaggle competittions and writing well in Python coding to prepare him for understanding messy data sets. He feels that academia is solitary and that data science is a collaborative field. He does not regret grad school as it taught him how to be self-motivated nd to keep on teaching one-self new skills in data science and  grad school gave him confidence to pull through  when models break down and failure happens but to keep on trying until you develop understanding and learn those necessary skills to be effective.\n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 -  Programming Lab \n",
    " 1. Lab is completed for week 1 which includes the output results for Exercise 4 for MovieLens\n",
    "  * Need asssistance with code for computing 'Total_servings' = beer + wine + spirits to add and remove a new calculated column(field) in python).\n",
    " \n",
    "## Course Project\n",
    " \n",
    " 1.Why are Asian women between aged 40-50 more likely to be diagnosed with breast cancer from migrant backgrounds?\n",
    "  * http://www.sbs.com.au/news/article/2016/10/14/asian-women-more-likely-be-diagnosed-breast-cancer-younger- age-study-finds \n",
    "  * Obtain data from Cancer institute http://www.statistics.cancerinstitute.org.au/\n",
    "  * Outcome to achieve is to uncover patterns to prevent breast cancer e.g lifestyle, diet, sleep, genetics and workshop in the community to spread awareness\n",
    "  * Modelling techniques include machine learning,  multiple regression, clustering\n",
    "  \n",
    "2. How to prevent stroke/seizure, early dementia or alzheimer's disease when combined with lifestyle of type 2 diabetes for the elderly aged 68 and above?\n",
    "   * Obtain dataset from: National stroke foundation or data.gov\n",
    "   * To achieve an outcome to understand how to workshop for the community undertand if their is a correlation with stroke and diabetes(type 2) and diabetes with dementia as the population ages in Australia or US\n",
    "   * Modelling techniques include regression, clustering\n",
    "   \n",
    "3. Track the patterns of storms and floods in NSW to understand weather patterns and other indicators to reduce Home Contents and Motor insurance claims for catastrophes.\n",
    "   * obtain data: NSW Stormtracker on www.data.gov.au\n",
    "   * To help reduce claims on catastrophes\n",
    "   * Modelling techniques include machine learning and clustering\n",
    "   \n",
    "4. Track the hospital performance in NSW for 2014, 2015 and 2016 based on Emergency admission and Elective surgery admission\n",
    "   * obtain data from data.gov.au eg. http://data.nsw.gov.au/data/dataset/hospital-quarterly-performance-of-nsw-public-hospitals-october-to-december-2015\n",
    "   * Want to understand the key performance indicators for patients suffering from diabetes, stroke or dementia to educate the aging community\n",
    "   * Modelling techniques to include regression, clustering, classification, machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Four - Movie Lens Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'users' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0a401a29e72f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 1.for each occupation in 'users', count the number of occurrences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0musers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moccupation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 2.for each occupation, calculate the mean age\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'users' is not defined"
     ]
    }
   ],
   "source": [
    "#### Solutions or Output is saved under Lab - Week 1-Pandas- wendy-wong.ipynb file.\n",
    "\n",
    "# 1.for each occupation in 'users', count the number of occurrences\n",
    "\n",
    "users.occupation.value_counts()\n",
    "\n",
    "# 2.for each occupation, calculate the mean age\n",
    "users.age.mean()\n",
    "print users.age.mean()\n",
    "\n",
    "# 3.for each occupation, calculate the minimum and maximum ages\n",
    "\n",
    "print users.age.min()\n",
    "print users.age.max()\n",
    "\n",
    "# 4.for each combination of occupation and gender, calculate the mean age\n",
    "\n",
    "users[users.gender.isin(['M'])] \n",
    "print users[(users.gender=='M')].age.mean()\n",
    "users[users.gender.isin(['F'])] \n",
    "print users[(users.gender=='F')].age.mean()\n",
    "\n",
    "# 5.randomly sample a DataFrame\n",
    "\n",
    "user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "users = pd.read_table('u.user', sep='|', header=None, names=user_cols, index_col='user_id', dtype={'zip_code':str})\n",
    "users = pd.read_table(np.random.rand(6,3),indexing=['user_id','age', 'gender', 'occupation', 'zip_code'])\n",
    "users = np.arrange(6*3).reshape((6,3))\n",
    "users = np.random.permutation(6)\n",
    "users\n",
    "\n",
    "# 6.detect duplicate users\n",
    "\n",
    "user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "users = pd.read_table('u.user', sep='|', header=None, names=user_cols, index_col='user_id', dtype={'zip_code':str})\n",
    "users = pd.read_table(np.random.rand(6,3),indexing=['user_id','user_id', 'gender', 'gender', 'zip_code','zip_code'])\n",
    "users\n",
    "users.ix['gender']\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
