{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYD DAT 6 \n",
    "\n",
    "## Homework - Due Monday 28th November 2016\n",
    "\n",
    "#### Course Project homework\n",
    "Share with a me a Jupyter notebook containing the following:\n",
    "* Data read into python in a data frame\n",
    "* A statistical summary of your data\n",
    "* A visualisation of your data\n",
    "* One of the following with your data; Linear or Logistic Regression (with regularization), or Clustering.\n",
    "* A written summary at the end describing your data\n",
    "\n",
    "#### Bonus\n",
    "Pick one data science topic that interests you, could be an article, or how a Kaggle competition was won, or an article incorporating data journalism. Write a short blog post (2 pages) with some visualisations where you discuss what was interesting.\n",
    "\n",
    "**Instructions: share the notebook and any other docuements with your name on the file e.g. _alasdaird.ipynb.\n",
    "Then commit this in your local repository, push it to your github account and create a pull request so I can see your work. Remeber if you get stuck to look at the slides going over Fork, Clone, Commit, Push and Pull request.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes on my homework\n",
    "\n",
    "Hi! I am afraid I can't display the data as it's confidential. I hope the code below is enough to show you my approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data read into python in a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### Get data\n",
    "\n",
    "### Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn.ensemble as ske\n",
    "import os\n",
    "from sklearn import tree, cross_validation\n",
    "\n",
    "\n",
    "### Get data\n",
    "\n",
    "## Set working directory\n",
    "# os.getcwd()\n",
    "os.chdir('/Users/muhsinkarim/Python/Projects/general_assembly/project_how_staff_sell')\n",
    "\n",
    "## Get data - select CSV by Department\n",
    "# Copy paste from R directory\n",
    "\n",
    "df = pd.read_csv('my_file.csv', index_col='StaffId', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A statistical summary of your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some exmaples of summarising my data\n",
    "\n",
    "## View first ten rows\n",
    "data.head(n=10)\n",
    "\n",
    "\n",
    "## Sales by staff\n",
    "byStaff = df.groupby('Staff')\n",
    "byStaff['Sales'].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A visualisation of your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Pairs plots\n",
    "\n",
    "## Select features\n",
    "dfPp = df[['Sales', 'Price', 'DailySales', 'DailyPrice', 'DailyItems', 'Experience']]\n",
    "\n",
    "## Plot         \n",
    "pd.tools.plotting.scatter_matrix(dfPp, alpha=0.2, figsize=(12, 12))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression (with regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Features and target\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df.Revenue\n",
    "\n",
    "\n",
    "### Split the data into training and testing sets\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "\n",
    "### Linear regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "## Predicting the text set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "## Visualise the training results\n",
    "test_values = y_test.values\n",
    "plt.scatter(test_values, y_pred, color='blue')\n",
    "plt.title('Actual test values vs predictions from regression model')\n",
    "plt.xlabel('Actual test values')\n",
    "plt.ylabel('Prediction values')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "### Regression results\n",
    "\n",
    "import statsmodels.formula.api as sm \n",
    "\n",
    "## Include a column of ones as constant not included in this library\n",
    "X1 = np.append(arr = np.ones((len(X), 1)).astype(int), values = X, axis=1)\n",
    "\n",
    "## View regression results\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X1).fit()\n",
    "regressor_OLS.summary()\n",
    "\n",
    "==============================================================================\n",
    "Dep. Variable:                Revenue   R-squared:                       0.482\n",
    "Model:                            OLS   Adj. R-squared:                  0.481\n",
    "Method:                 Least Squares   F-statistic:                     527.0\n",
    "Date:                Sun, 04 Dec 2016   Prob (F-statistic):               0.00\n",
    "Time:                        22:25:21   Log-Likelihood:                -51472.\n",
    "No. Observations:                3978   AIC:                         1.030e+05\n",
    "Df Residuals:                    3970   BIC:                         1.030e+05\n",
    "Df Model:                           7                                         \n",
    "Covariance Type:            nonrobust                                         \n",
    "==============================================================================\n",
    "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
    "------------------------------------------------------------------------------\n",
    "const       1.095e+04   5696.549      1.923      0.055      -216.388  2.21e+04\n",
    "x1             0.7082      0.015     47.679      0.000         0.679     0.737\n",
    "x2            12.9390     30.340      0.426      0.670       -46.544    72.422\n",
    "x3          -155.7974     43.503     -3.581      0.000      -241.088   -70.507\n",
    "x4          2140.7911   6747.835      0.317      0.751     -1.11e+04  1.54e+04\n",
    "x5         -6238.4259   6595.694     -0.946      0.344     -1.92e+04  6692.839\n",
    "x6           857.7156   6282.881      0.137      0.891     -1.15e+04  1.32e+04\n",
    "x7          -803.0764   3635.169     -0.221      0.825     -7930.049  6323.896\n",
    "==============================================================================\n",
    "Omnibus:                     1036.736   Durbin-Watson:                   1.893\n",
    "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            16172.304\n",
    "Skew:                           0.816   Prob(JB):                         0.00\n",
    "Kurtosis:                      12.742   Cond. No.                     1.20e+06\n",
    "==============================================================================\n",
    "\n",
    "\n",
    "### Regularisation\n",
    "\n",
    "## make predictions and evaluate\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "print 'RMSE (no regularization) =', np.sqrt(metrics.mean_squared_error(y_test, y_pred)) # Error between prediction and reality\n",
    "    # RMSE (no regularization) = 104107.227787\n",
    "\n",
    "## Ridge Regression Model\n",
    "# ridge regression (alpha must be positive, larger means more regularization)\n",
    "from sklearn.linear_model import Ridge\n",
    "rreg = Ridge(alpha=10.0, normalize=True) # How do oyo pick alpha\n",
    "rreg.fit(X_train, y_train)\n",
    "rreg.coef_\n",
    "preds = rreg.predict(X_test)\n",
    "print 'RMSE (Ridge reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds))\n",
    "    # RMSE (Ridge reg.) = 137812.016982\n",
    "    \n",
    "# use RidgeCV to select best alpha\n",
    "from sklearn.linear_model import RidgeCV\n",
    "alpha_range = 10.**np.arange(-2, 3)\n",
    "rregcv = RidgeCV(normalize=True, scoring='mean_squared_error', alphas=alpha_range, cv=5) # You added cv=5\n",
    "rregcv.fit(X_train, y_train)\n",
    "rregcv.alpha_\n",
    "preds = rregcv.predict(X_test)\n",
    "print 'RMSE (Ridge CV reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds))\n",
    "    # RMSE (Ridge CV reg.) = 104101.712864\n",
    "    \n",
    "## Lasso Regression Model\n",
    "# lasso (alpha must be positive, larger means more regularization)\n",
    "from sklearn.linear_model import Lasso\n",
    "las = Lasso(alpha=0.01, normalize=True)\n",
    "las.fit(X_train, y_train)\n",
    "las.coef_\n",
    "preds = las.predict(X_test)\n",
    "print 'RMSE (Lasso reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds))\n",
    "    # RMSE (Lasso reg.) = 104107.305674\n",
    "\n",
    "## use LassoCV to select best alpha (tries 100 alphas by default)\n",
    "from sklearn.linear_model import LassoCV\n",
    "alpha_range = 0.01**np.arange(-2, 3) # Different scales of alpha - use function grid_search()\n",
    "lascv = LassoCV(normalize=True, alphas=alpha_range, cv=5) # You added cv=5\n",
    "lascv.fit(X_train, y_train)\n",
    "lascv.alpha_\n",
    "lascv.coef_\n",
    "preds = lascv.predict(X_test)\n",
    "print 'RMSE (Lasso CV reg.) =', np.sqrt(metrics.mean_squared_error(y_test, preds))\n",
    "lascv.alpha_\n",
    "    # RMSE (Lasso CV reg.) = 104115.263904\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A written summary at the end describing your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression results above indicate that features x1 and x3 are significant influences of the target Revenue. Regression coefficients represent the mean change in the response variable for one unit of change in the predictor variable while holding other predictors in the model constant. Thus, a mean change of 0.7 in Revenue is expected for one unit change of predictor x1. A mean change of -155.8 in Revenue is expected for one unit change of predictor x3.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
