{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and Regression Trees\n",
    "\n",
    "## Monday November 7, 2016\n",
    "\n",
    "\n",
    "\n",
    "Fill in missing code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read, Explore, and Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "titanic = pd.______('titanic.csv')\n",
    "\n",
    "# Take a  selection of the features\n",
    "d = titanic[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for missing values in all columns\n",
    "d._____().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check for missing values in Age column, after grouping by other columns\n",
    "d.groupby(['Sex', 'Pclass']).Age.apply(lambda x: x.isnull().sum()) / d.groupby(['Sex', 'Pclass']).Age.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill in missing values with the mean value (use .fillna())\n",
    "d['___'] = d['___'].fillna(d['___'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert any text categorical features to numeric for scikit learn\n",
    "d['Sex'] = np.____(d.Sex == 'female', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore the data to identify trends in characteristics of survivors\n",
    "d.Survived.value_counts()                    # How many people lived and died\n",
    "d.Survived.mean()                            # The survival rate for everyone\n",
    "d.groupby('Sex').Survived.mean()             # By Sex: women have higher survival rates\n",
    "d.groupby('Pclass').Survived.mean()          # By Pclass: 1st class passengers have higher survival rates\n",
    "d.groupby(['Sex', 'Pclass']).Survived.mean() # By Sex and Pclass: Women in the 1st and 2nd classes had the highest survival rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a new feature representing whether the Spouse was on board\n",
    "d['Spouse'] = ((d.Age > 18) & (d.SibSp >= 1)).astype(int)\n",
    "d.Spouse.value_counts()\n",
    "d.groupby(['Pclass', 'Spouse']).Survived.mean() # Having a spouse appears to increase survival in the 1st class only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into training and test datasets, and build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now, split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = _________________(d,survived, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a decision tree classifier object (start out with a small tree for interpretability)\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1, max_depth=2)\n",
    "\n",
    "# Fit the decision tree classifier\n",
    "ctree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How to interpret the diagram?\n",
    "ctree.classes_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a plotting function that will plot a nice confusion matrix see: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load confusion_matrix_nice.py\n",
    "# from confusion_matrix_nice import plot_confusion_matrix\n",
    "%run confusion_matrix_nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the predictions (not the probabilities)\n",
    "y_pred_class = ctree.______(X_test)\n",
    "\n",
    "# plot an attractive confusion matrix\n",
    "cnf_mat = metrics.confusion_matrix(y_test, ________, labels = titanic.Survived.unique())\n",
    "class_labels = titanic.Survived.unique()\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_mat, class_labels,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a feature vector for reference. We will create fictional values for test observations. \n",
    "features = X_train.columns.tolist()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict what will happen for 1st class woman\n",
    "#features\n",
    "ctree.predict_proba([1, 1, 25, 0, 0, 0])\n",
    "ctree.predict([1, 1, 25, 0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Predict what will happen for a 3rd class man\n",
    "ctree.predict_proba([3, 0, 25, 0, 0, 0])\n",
    "ctree.predict([3, 0, 25, 0, 0, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Which features are the most important?\n",
    "ctree.__________\n",
    "\n",
    "# Make a Dataframe out of the features and the importance measure for the features\n",
    "pd.DataFrame(zip(features, ctree.____________)).sort_index(by=1, ascending=False)\n",
    "\n",
    "# Make predictions on the test set\n",
    "preds = ctree.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "metrics.accuracy_score(y_test, preds)\n",
    "\n",
    "# Confusion matrix\n",
    "pd.crosstab(y_test, preds, rownames=['actual'], colnames=['predicted'])\n",
    "\n",
    "# Make predictions on the test set using predict_proba\n",
    "probs = ctree._________(X_test)[:,1]\n",
    "\n",
    "# Calculate the AUC metric\n",
    "metrics.roc_auc_score(y_test, probs)\n",
    "\n",
    "# Decision Trees have notorouisly high variance, so what can we do\n",
    "# to better estimate the out of sample error of a high variance model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare against Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1, max_depth=2)\n",
    "\n",
    "# compare AUC using cross-validation\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "cross_val_score(logreg, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "cross_val_score(ctree, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "\n",
    "# so far logistic regression is winning..\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FINE-TUNING THE TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# check CV score for max depth = 3\n",
    "ctree = tree.DecisionTreeClassifier(max_depth=3)\n",
    "np.mean(cross_val_score(ctree, d, survived, cv=5, scoring='roc_auc'))\n",
    "\n",
    "# check CV score for max depth = 10\n",
    "ctree = tree.DecisionTreeClassifier(max_depth=10)\n",
    "np.mean(cross_val_score(ctree, d, survived, cv=5, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Conduct a grid search for the best tree depth\n",
    "ctree = tree.DecisionTreeClassifier(random_state=1)\n",
    "depth_range = range(1, 20)\n",
    "param_grid = dict(max_depth=depth_range)\n",
    "grid = GridSearchCV(ctree, param_grid, cv=5, scoring='roc_auc')\n",
    "grid.fit(d, survived)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Check out the scores of the grid search\n",
    "grid_mean_scores = [result[1] for result in grid.grid_scores_]\n",
    "\n",
    "\n",
    "# Plot the results of the grid search\n",
    "plt.figure()\n",
    "plt.plot(depth_range, grid_mean_scores)\n",
    "plt.hold(True)\n",
    "plt.grid(True)\n",
    "plt.plot(grid.best_params_['max_depth'], grid.best_score_, 'ro', markersize=12, markeredgewidth=1.5,\n",
    "         markerfacecolor='None', markeredgecolor='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get the best estimator\n",
    "best = grid.best_estimator_\n",
    "\n",
    "cross_val_score(best, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "cross_val_score(logreg, d, survived, cv=10, scoring='roc_auc').mean()\n",
    "\n",
    "\n",
    "# Still not as good as Logistic Regression.. \n",
    "# Let's try something else\n",
    "\n",
    "\n",
    "\n",
    "### EXERCISE ###\n",
    "''' Use Grid Search try scan over three parameters\n",
    "1. max_depth:     from 1 to 20\n",
    "2. criterion:     (either 'gini' or 'entropy')\n",
    "3. max_features : range (1,5)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Decision trees (like many other classification models)\n",
    "# can also be used for regression!\n",
    "\n",
    "\n",
    "drinks = pd.read_csv('drinks.csv', na_filter=False)\n",
    "\n",
    "drinks\n",
    "\n",
    "# Make dummy columns for each of the 6 regions\n",
    "for continent_ in ['AS', 'NA', 'EU', 'AF', 'SA', 'OC']:\n",
    "    drinks[continent_] = drinks['continent'] == continent_\n",
    "\n",
    "drinks\n",
    "\n",
    "\n",
    "del drinks['continent']\n",
    "del drinks['country']\n",
    "del drinks['total_litres_of_pure_alcohol'] # this doesn't seem fair does it?\n",
    "\n",
    "X = drinks.drop('wine_servings', axis=1)\n",
    "y = drinks['wine_servings']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\n",
    "\n",
    "\n",
    "rtree = tree.DecisionTreeRegressor()\n",
    "\n",
    "rtree.fit(X_train, y_train)\n",
    "rtree.predict(X_test)\n",
    "\n",
    "scores = - cross_val_score(rtree, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "mse_scores = scores\n",
    "mse_scores\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "rmse_scores\n",
    "rmse_scores.mean()\n",
    "\n",
    "wine_mean = y.mean()\n",
    "wine_mean\n",
    "\n",
    "features = X.columns\n",
    "pd.DataFrame(zip(features, rtree.feature_importances_)).sort_values(by=1, ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
